{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch tensors can be converted to NumPy arrays and vice versa very efficiently.\n",
    "- By doing so, we can take advantage of the huge swath of functionality in the wider Python ecosystem that has built up around the NumPy array type.\n",
    "- This **zero-copy interoperability** with NumPy arrays is dur to the **storage system working with the Python buffer protocol**: https://docs.python.org/3/c-api/buffer.html\n",
    "    - Python buffer protocolはまだ分かっていないが。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.ones(3, 4)\n",
    "points_np = points.numpy()\n",
    "points_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Interestingly, **the returned array shares the same underlying buffer with the tensor storage**.\n",
    "- This means the `numpy` method can be effectively executed at basically no cost, as long as the data sits in CPU RAM.\n",
    "- It also means **modifying the NumPy array will lead to a change in the originating tensor**.\n",
    "- **If the tensor is allocated on the GPU, PyTorch will make a copy of the content of the tensor into NumPy array allocated on the CPU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.from_numpy(points_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **While the default numeric type in PyTorch is 32-bit floating-point, for NumPy it is 64-bit**.\n",
    "- We usually want to use 32-bit floating-points, so we need to make sure we have tensors of `dtype torch.float` after converting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
