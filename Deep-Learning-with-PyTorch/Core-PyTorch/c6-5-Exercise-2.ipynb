{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The third-hardest problem in physics is finding a proper wine to celebrate discoveries. Load the wine data from chapter 4, and create a new model with the appropriate number of input parameters.\n",
    "    - How long does it take to train compared to the temperature data we have been using?\n",
    "    - Can you explain what factors contribute to the training times?\n",
    "    - Can you get the loss to decrease while training on this dataset?\n",
    "    - How would you go about graphing this dataset?\n",
    "- まずload data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_path = '../data/p1ch4/tabular-wine/winequality-white.csv'\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=';',\n",
    "                        skiprows=1)\n",
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "data = wineq[:, :-1]\n",
    "target = wineq[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 11]), torch.Size([4898]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 取りあえずtargetになっているqualityはcontinuous valueと見る。\n",
    "- dataをnormalizeする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1761e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
       "         -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
       "          1.3422e-03, -8.2419e-01],\n",
       "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
       "         -4.3677e-01, -3.3663e-01],\n",
       "        ...,\n",
       "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
       "         -2.6153e-01, -9.0545e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
       "         -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
       "         -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_var = torch.var(data, dim=0)\n",
    "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- targetをunsqueezeする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_unsqueezed = target.unsqueeze(1)\n",
    "target_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training, validation dataに分ける："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3919, 11]), torch.Size([979, 11]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = data.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "data_train = data_normalized[train_indices]\n",
    "target_train = target_unsqueezed[train_indices]\n",
    "\n",
    "data_val = data_normalized[val_indices]\n",
    "target_val = target_unsqueezed[val_indices]\n",
    "\n",
    "data_train.shape, data_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model, loss, training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "        \n",
    "        t_p_val = model(t_u_val)\n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == 1 or epoch % 1000 == 0:\n",
    "            print(f'Epoch {epoch}, Training loss {loss_train.item():.4f},'\n",
    "                 f' Validation loss {loss_val.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 35.1173, Validation loss 34.7226\n",
      "Epoch 1000, Training loss 0.5710, Validation loss 0.5606\n",
      "Epoch 2000, Training loss 0.5558, Validation loss 0.5472\n",
      "Epoch 3000, Training loss 0.5500, Validation loss 0.5415\n",
      "Epoch 4000, Training loss 0.5454, Validation loss 0.5370\n",
      "Epoch 5000, Training loss 0.5416, Validation loss 0.5332\n"
     ]
    }
   ],
   "source": [
    "seq_model = nn.Sequential(nn.Linear(11, 20),\n",
    "                         nn.Tanh(),\n",
    "                         nn.Linear(20, 1))\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3)\n",
    "\n",
    "training_loop(n_epochs=5000,\n",
    "             optimizer=optimizer,\n",
    "             model=seq_model,\n",
    "             loss_fn=nn.MSELoss(),\n",
    "             t_u_train=data_train,\n",
    "             t_u_val=data_val,\n",
    "             t_c_train=target_train,\n",
    "             t_c_val=target_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習時間は明らかに長くなった。具体的な時間は図っていない。\n",
    "- input featureが11になったこと、学習データが多くなったことで、学習時間が長くなったでしょう。\n",
    "- featureが11なので、温度計の例のような可視化はできない。普段はtraining lossやvalidation lossをplotするでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
