{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take several pictures of red, blue, and green items with your phone or other digital camera (or download some from the internet, if a camera isn’t available).\n",
    "    - Load each image, and convert it to a tensor.\n",
    "    - For each image tensor, use the .mean() method to get a sense of how bright the image is.\n",
    "    - Take the mean of each channel of your images. Can you identify the red, green, and blue items from only the channel averages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3216, 3212, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr = imageio.imread('../data/p1ch4/exercise/Madonna_of_the_Magnificat.png')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4th channelはalpha channelらしい。allows for transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3216, 3212, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.from_numpy(img_arr)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t[:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3216, 3212, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t_rgb = img_t[:,:,:3].float()\n",
    "img_t_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(79.4028)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t_rgb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(105.7936), tensor(80.7073), tensor(51.7076)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = [torch.mean(img_t_rgb[:,:,i]) for i in range(3)]\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select a relatively large file containing Python source code.\n",
    "    - Build an index of all the words in the source file (feel free to make your tokenization as simple or as complex as you like; we suggest starting with replacing r\"[^a-zA-Z0-9_]+\" with spaces).\n",
    "    - Compare your index with the one we made for Pride and Prejudice. Which is larger?\n",
    "    - Create the one-hot encoding for the source code file.\n",
    "    - What information is lost with this encoding? How does that information compare to what’s lost in the Pride and Prejudice encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/p1ch4/exercise/augmentation.py', encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_re = re.sub(r'[^a-zA-Z0-9_]+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(input_str):\n",
    "    punctuation = '.,;:\"!?”“_-' # ”“は本からコピーしてきた。。。\n",
    "    word_list = input_str.lower().replace('\\n',' ').split()\n",
    "    word_list = [word.strip(punctuation) for word in word_list]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = clean_words(text_re)\n",
    "word_list = sorted(set(text_words))\n",
    "word2index_dict = {word: i for (i, word) in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 1329, 265)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index_dict), len(text_words), len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '125': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '360': 5,\n",
       " '3d': 6,\n",
       " '4': 7,\n",
       " '5': 8,\n",
       " '8': 9,\n",
       " 'a': 10,\n",
       " 'abs': 11,\n",
       " 'affine': 12,\n",
       " 'after': 13,\n",
       " 'and': 14,\n",
       " 'angle': 15,\n",
       " 'append': 16,\n",
       " 'apply': 17,\n",
       " 'args': 18,\n",
       " 'around': 19,\n",
       " 'as': 20,\n",
       " 'assert': 21,\n",
       " 'autograd': 22,\n",
       " 'axes': 23,\n",
       " 'axis_vector': 24,\n",
       " 'b': 25,\n",
       " 'back': 26,\n",
       " 'backends': 27,\n",
       " 'be': 28,\n",
       " 'before': 29,\n",
       " 'between': 30,\n",
       " 'bilinear': 31,\n",
       " 'blob': 32,\n",
       " 'c': 33,\n",
       " 'c1': 34,\n",
       " 'can': 35,\n",
       " 'catch_warnings': 36,\n",
       " 'ceil': 37,\n",
       " 'center': 38,\n",
       " 'center_list': 39,\n",
       " 'clamp': 40,\n",
       " 'clamphsv': 41,\n",
       " 'clamps': 42,\n",
       " 'clone': 43,\n",
       " 'com': 44,\n",
       " 'contiguous': 45,\n",
       " 'coordinate': 46,\n",
       " 'coordinates': 47,\n",
       " 'coords': 48,\n",
       " 'cos': 49,\n",
       " 'cpu': 50,\n",
       " 'crop_int': 51,\n",
       " 'crop_list': 52,\n",
       " 'croptoshape': 53,\n",
       " 'cudnn': 54,\n",
       " 'cval': 55,\n",
       " 'debug': 56,\n",
       " 'def': 57,\n",
       " 'device': 58,\n",
       " 'do': 59,\n",
       " 'down': 60,\n",
       " 'dtype': 61,\n",
       " 'else': 62,\n",
       " 'end_int': 63,\n",
       " 'everything': 64,\n",
       " 'expand_as': 65,\n",
       " 'false': 66,\n",
       " 'fill': 67,\n",
       " 'filters': 68,\n",
       " 'flatten': 69,\n",
       " 'flip': 70,\n",
       " 'float32': 71,\n",
       " 'float64': 72,\n",
       " 'floor': 73,\n",
       " 'following': 74,\n",
       " 'for': 75,\n",
       " 'from': 76,\n",
       " 'from_numpy': 77,\n",
       " 'function': 78,\n",
       " 'gaussian_filter': 79,\n",
       " 'getlogger': 80,\n",
       " 'github': 81,\n",
       " 'h': 82,\n",
       " 'h_max': 83,\n",
       " 'h_min': 84,\n",
       " 'https': 85,\n",
       " 'hue': 86,\n",
       " 'i': 87,\n",
       " 'if': 88,\n",
       " 'ignore': 89,\n",
       " 'image': 90,\n",
       " 'image_hsv': 91,\n",
       " 'image_list': 92,\n",
       " 'import': 93,\n",
       " 'in': 94,\n",
       " 'indices': 95,\n",
       " 'info': 96,\n",
       " 'input': 97,\n",
       " 'input_flat': 98,\n",
       " 'input_transformed': 99,\n",
       " 'int': 100,\n",
       " 'int64': 101,\n",
       " 'interpolation': 102,\n",
       " 'ints': 103,\n",
       " 'is': 104,\n",
       " 'just': 105,\n",
       " 'l': 106,\n",
       " 'lambda': 107,\n",
       " 'len': 108,\n",
       " 'licensed': 109,\n",
       " 'log': 110,\n",
       " 'logconf': 111,\n",
       " 'logging': 112,\n",
       " 'long': 113,\n",
       " 'm': 114,\n",
       " 'make': 115,\n",
       " 'map': 116,\n",
       " 'master': 117,\n",
       " 'math': 118,\n",
       " 'matrix': 119,\n",
       " 'max': 120,\n",
       " 'meshgrid': 121,\n",
       " 'might': 122,\n",
       " 'min': 123,\n",
       " 'mit': 124,\n",
       " 'mm': 125,\n",
       " 'mode': 126,\n",
       " 'mul': 127,\n",
       " 'n': 128,\n",
       " 'name': 129,\n",
       " 'ncullen93': 130,\n",
       " 'ndimage': 131,\n",
       " 'nearest': 132,\n",
       " 'new': 133,\n",
       " 'new_coords': 134,\n",
       " 'new_image': 135,\n",
       " 'new_list': 136,\n",
       " 'new_shape': 137,\n",
       " 'noise': 138,\n",
       " 'noise_max': 139,\n",
       " 'noise_min': 140,\n",
       " 'none': 141,\n",
       " 'normal': 142,\n",
       " 'not': 143,\n",
       " 'np': 144,\n",
       " 'numpy': 145,\n",
       " 'odd': 146,\n",
       " 'of': 147,\n",
       " 'offset_cols': 148,\n",
       " 'offset_rows': 149,\n",
       " 'on': 150,\n",
       " 'once_differentiable': 151,\n",
       " 'order': 152,\n",
       " 'origin': 153,\n",
       " 'output': 154,\n",
       " 'pi': 155,\n",
       " 'prefilter': 156,\n",
       " 'prhist': 157,\n",
       " 'py': 158,\n",
       " 'rand': 159,\n",
       " 'random': 160,\n",
       " 'random_sample': 161,\n",
       " 'randomflip': 162,\n",
       " 'randomflip_transform_list': 163,\n",
       " 'randomhsvshift': 164,\n",
       " 'randomnoise': 165,\n",
       " 'randomoffset': 166,\n",
       " 'randomspin': 167,\n",
       " 'randomzoom': 168,\n",
       " 'randrange': 169,\n",
       " 'range': 170,\n",
       " 'range_tup': 171,\n",
       " 'repr': 172,\n",
       " 'reshape': 173,\n",
       " 'return': 174,\n",
       " 'rot90': 175,\n",
       " 'rotate': 176,\n",
       " 'round': 177,\n",
       " 's': 178,\n",
       " 's_max': 179,\n",
       " 's_min': 180,\n",
       " 'scale': 181,\n",
       " 'scale_max': 182,\n",
       " 'scale_min': 183,\n",
       " 'scipy': 184,\n",
       " 'setlevel': 185,\n",
       " 'shape': 186,\n",
       " 'shift': 187,\n",
       " 'simplefilter': 188,\n",
       " 'sin': 189,\n",
       " 'since': 190,\n",
       " 'size': 191,\n",
       " 'slice': 192,\n",
       " 'so': 193,\n",
       " 'square': 194,\n",
       " 'start_int': 195,\n",
       " 'stride': 196,\n",
       " 'sum': 197,\n",
       " 't': 198,\n",
       " 'take': 199,\n",
       " 'tensor': 200,\n",
       " 'th_affine3d': 201,\n",
       " 'th_flatten': 202,\n",
       " 'th_iterproduct': 203,\n",
       " 'th_trilinear_interp3d': 204,\n",
       " 'the': 205,\n",
       " 'then': 206,\n",
       " 'theta': 207,\n",
       " 'torch': 208,\n",
       " 'torch_augment': 209,\n",
       " 'torchsample': 210,\n",
       " 'transform': 211,\n",
       " 'transform_bits': 212,\n",
       " 'transformation': 213,\n",
       " 'trilinear': 214,\n",
       " 'true': 215,\n",
       " 'using': 216,\n",
       " 'util': 217,\n",
       " 'utils': 218,\n",
       " 'v': 219,\n",
       " 'v_max': 220,\n",
       " 'v_min': 221,\n",
       " 'vals_000': 222,\n",
       " 'vals_001': 223,\n",
       " 'vals_010': 224,\n",
       " 'vals_011': 225,\n",
       " 'vals_100': 226,\n",
       " 'vals_101': 227,\n",
       " 'vals_110': 228,\n",
       " 'vals_111': 229,\n",
       " 'view': 230,\n",
       " 'view_as': 231,\n",
       " 'warn': 232,\n",
       " 'warnings': 233,\n",
       " 'we': 234,\n",
       " 'with': 235,\n",
       " 'wraps': 236,\n",
       " 'x': 237,\n",
       " 'x0': 238,\n",
       " 'x0_ix': 239,\n",
       " 'x1': 240,\n",
       " 'x1_ix': 241,\n",
       " 'x_mapped': 242,\n",
       " 'xd': 243,\n",
       " 'xm1': 244,\n",
       " 'y': 245,\n",
       " 'y0': 246,\n",
       " 'y0_ix': 247,\n",
       " 'y1': 248,\n",
       " 'y1_ix': 249,\n",
       " 'yd': 250,\n",
       " 'ym1': 251,\n",
       " 'z': 252,\n",
       " 'z0': 253,\n",
       " 'z0_ix': 254,\n",
       " 'z1': 255,\n",
       " 'z1_ix': 256,\n",
       " 'zd': 257,\n",
       " 'zeros': 258,\n",
       " 'zeros_like': 259,\n",
       " 'zimage': 260,\n",
       " 'zm1': 261,\n",
       " 'zoom': 262,\n",
       " 'zoom_shape': 263,\n",
       " 'zoomtoshape': 264}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0   93 import\n",
      " 1  118 math\n",
      " 2   93 import\n",
      " 3  160 random\n",
      " 4   93 import\n",
      " 5  233 warnings\n",
      " 6   93 import\n",
      " 7  145 numpy\n",
      " 8   20 as\n",
      " 9  144 np\n",
      "10   93 import\n",
      "11  184 scipy\n",
      "12  131 ndimage\n",
      "13   93 import\n",
      "14  208 torch\n",
      "15   76 from\n",
      "16  208 torch\n",
      "17   22 autograd\n",
      "18   93 import\n",
      "19   78 function\n",
      "20   76 from\n",
      "21  208 torch\n",
      "22   22 autograd\n",
      "23   78 function\n",
      "24   93 import\n",
      "25  151 once_differentiable\n",
      "26   93 import\n",
      "27  208 torch\n",
      "28   27 backends\n",
      "29   54 cudnn\n",
      "30   20 as\n",
      "31   54 cudnn\n",
      "32   76 from\n",
      "33  217 util\n",
      "34  111 logconf\n",
      "35   93 import\n",
      "36  112 logging\n",
      "37  110 log\n",
      "38  112 logging\n",
      "39   80 getlogger\n",
      "40  129 name\n",
      "41  110 log\n",
      "42  185 setlevel\n",
      "43  112 logging\n",
      "44  232 warn\n",
      "45  110 log\n",
      "46  185 setlevel\n",
      "47  112 logging\n",
      "48   96 info\n",
      "49  110 log\n",
      "torch.Size([1329, 265])\n"
     ]
    }
   ],
   "source": [
    "word_t = torch.zeros(len(text_words), len(word2index_dict))\n",
    "for i, word in enumerate(text_words):\n",
    "    word_index = word2index_dict[word]\n",
    "    word_t[i][word_index] = 1\n",
    "    if i < 50:\n",
    "        print('{:2} {:4} {}'.format(i, word_index, word))\n",
    "\n",
    "print(word_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
