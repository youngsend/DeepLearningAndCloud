{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As of mid-2019, the main PyTorch releases only have acceleration on GPUs that have support for CUDA.\n",
    "### 3.9.1 Managing a tensor's device attribute\n",
    "- In addition to `dtype`, a PyTorch `Tensor` also has the notion of `device`, which is **where on the computer the tensor data is placed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Copy a tensor created on the CPU onto the GPU using the `to` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_gpu = points.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Doing so returns a new tensor that has the same numerical data, but **stored in the RAM of the GPU**, rather than in regular system RAM.\n",
    "- **In almost all cases, CPU- and GPU-based tensors expose the same user-facing API**, making it much easier to write code that is agnostic to where, exactly, the heavy number crunching(噛み砕く「かみくだく」) is running.\n",
    "- If our machine has more than one GPU, we can also decide on which GPU we allocate the tensor by passing a zero-based integer identifying the GPU on the machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.to(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = 2 * points.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上記計算の発生したこと：\n",
    "    - The `points` tensor is copied to the GPU.\n",
    "    - A new tensor is allocated on the GPU and used to store the result of the multiplication.\n",
    "    - A handle to that GPU tensor is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points_gpu + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The addition is still performed on the GPU, and no information flows to the CPU (**unless we print or access the resulting tensor**).\n",
    "- In order to move the tensor back to the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_cpu = points_gpu.to(device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can also use the shorthand methods `cpu` and `cuda` instead of the `to` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.cuda() # defaults to GPU index 0\n",
    "points_gpu = points.cuda(0)\n",
    "points_cpu = points_gpu.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By using the `to` method, we can change the placement and the data type simultaneouly by providing both `device` and `dtype` as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
