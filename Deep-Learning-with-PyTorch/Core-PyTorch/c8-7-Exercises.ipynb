{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change our model to use a 5 × 5 kernel with kernel_size=5 passed to the nn.Conv2d constructor.\n",
    "    - What impact does this change have on the number of parameters in the model?\n",
    "    - Does the change improve or degrade overfitting?\n",
    "    - Read https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d.\n",
    "    - Can you describe what kernel_size=(1,3) will do?\n",
    "    - How does the model behave with such a kernel? やっていない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cifar2を用意する："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                   (0.2470, 0.2435, 0.2616))\n",
    "                          ]))\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                       (0.2470, 0.2435, 0.2616))\n",
    "                              ]))\n",
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "         for img, label in cifar10\n",
    "         if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "             for img, label in cifar10_val\n",
    "             if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kernel sizeを5にするので、paddingも２に変更するはず。\n",
    "- 一番目Linearのinput sizeはエラーメッセージから取るか。。でも変わらない気がする、paddingがあるから。サイズはmax poolingしかと関係ないはずだ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=kernel_size, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=kernel_size, padding=2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上記モデルがinput画像を処理できるかをテスト："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0445, -0.1149]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(kernel_size=5)\n",
    "img, _ = cifar2[0]\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 処理できたので、モデルは大丈夫そうだ！\n",
    "- parameter数は："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20906, [1200, 16, 3200, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- parameter数は主に5x5x3x16=1200, kernel sizeは5x5x3だ。input channelsを処理できるように。\n",
    "- training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "         else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "            datetime.datetime.now(), epoch, loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 03:05:51.072684 Epoch 1, Training loss 0.5387514252571544\n",
      "2020-12-30 03:05:53.797294 Epoch 10, Training loss 0.3192493832035429\n",
      "2020-12-30 03:05:56.822801 Epoch 20, Training loss 0.2778432199339958\n",
      "2020-12-30 03:05:59.859464 Epoch 30, Training loss 0.24807112464669404\n",
      "2020-12-30 03:06:02.878734 Epoch 40, Training loss 0.21821043374621943\n",
      "2020-12-30 03:06:05.895975 Epoch 50, Training loss 0.19998073959901075\n",
      "2020-12-30 03:06:08.939146 Epoch 60, Training loss 0.1797535287062074\n",
      "2020-12-30 03:06:11.950189 Epoch 70, Training loss 0.1627138643317921\n",
      "2020-12-30 03:06:14.945885 Epoch 80, Training loss 0.14478921819074897\n",
      "2020-12-30 03:06:17.927673 Epoch 90, Training loss 0.1261396531941025\n",
      "2020-12-30 03:06:20.933380 Epoch 100, Training loss 0.10748946671463122\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "model = Net(kernel_size=5).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(n_epochs=100,\n",
    "             optimizer=optimizer,\n",
    "             model=model,\n",
    "             loss_fn=loss_fn,\n",
    "             train_loader=train_loader,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.93\n",
      "Accuracy val: 0.88\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "        \n",
    "        print(\"Accuracy {}: {:.2f}\".format(name, correct / total))\n",
    "\n",
    "validate(model.to(device=torch.device('cpu')), train_loader=train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- overfittingは悪くなっている。つまり小さいkernelの方がgeneralizationが良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
